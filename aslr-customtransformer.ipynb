{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sklearn\nimport matplotlib.pyplot as plt\nimport json\nimport regex\nimport os\nfrom tqdm.notebook import tqdm\nimport math\nimport sys\nimport random\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import *\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-11T15:09:35.282272Z","iopub.execute_input":"2023-07-11T15:09:35.282886Z","iopub.status.idle":"2023-07-11T15:09:40.107209Z","shell.execute_reply.started":"2023-07-11T15:09:35.282841Z","shell.execute_reply":"2023-07-11T15:09:40.106053Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Read Character to Ordinal Encoding Mapping\nwith open('/kaggle/input/asl-fingerspelling/character_to_prediction_index.json') as json_file:\n    char2ord = json.load(json_file)\n\ndisplay(pd.Series(char2ord).to_frame('Ordinal Encoding'))","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:09:40.109121Z","iopub.execute_input":"2023-07-11T15:09:40.109732Z","iopub.status.idle":"2023-07-11T15:09:40.135083Z","shell.execute_reply.started":"2023-07-11T15:09:40.109697Z","shell.execute_reply":"2023-07-11T15:09:40.134146Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"   Ordinal Encoding\n                  0\n!                 1\n#                 2\n$                 3\n%                 4\n&                 5\n'                 6\n(                 7\n)                 8\n*                 9\n+                10\n,                11\n-                12\n.                13\n/                14\n0                15\n1                16\n2                17\n3                18\n4                19\n5                20\n6                21\n7                22\n8                23\n9                24\n:                25\n;                26\n=                27\n?                28\n@                29\n[                30\n_                31\na                32\nb                33\nc                34\nd                35\ne                36\nf                37\ng                38\nh                39\ni                40\nj                41\nk                42\nl                43\nm                44\nn                45\no                46\np                47\nq                48\nr                49\ns                50\nt                51\nu                52\nv                53\nw                54\nx                55\ny                56\nz                57\n~                58","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ordinal Encoding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th></th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>!</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>#</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>$</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>%</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>&amp;</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>'</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>(</th>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>)</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>*</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>+</th>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>,</th>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>-</th>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>.</th>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>/</th>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>:</th>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>;</th>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>=</th>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>?</th>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>@</th>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>[</th>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>_</th>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>a</th>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>b</th>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>c</th>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>d</th>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>e</th>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>f</th>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>g</th>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>h</th>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>i</th>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>j</th>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>k</th>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>l</th>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>m</th>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>n</th>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>o</th>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>p</th>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>q</th>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>r</th>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>s</th>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>t</th>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>u</th>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>v</th>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>w</th>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>x</th>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>y</th>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>z</th>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>~</th>\n      <td>58</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"frames=np.load('/kaggle/input/aslr-hands/X.npy', allow_pickle=True)\nphrases = np.load('/kaggle/input/aslr-hands/Y.npy', allow_pickle=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:09:40.136490Z","iopub.execute_input":"2023-07-11T15:09:40.136800Z","iopub.status.idle":"2023-07-11T15:10:11.303541Z","shell.execute_reply.started":"2023-07-11T15:09:40.136775Z","shell.execute_reply":"2023-07-11T15:10:11.302191Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# GLOBAL CONFIG","metadata":{}},{"cell_type":"code","source":"# Ensure deterministic behavior\ntorch.backends.cudnn.deterministic = True\nrandom.seed(hash(\"setting random seeds\") % 2**32 - 1)\nnp.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\ntorch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\ntorch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:11.309863Z","iopub.execute_input":"2023-07-11T15:10:11.310794Z","iopub.status.idle":"2023-07-11T15:10:11.334761Z","shell.execute_reply.started":"2023-07-11T15:10:11.310753Z","shell.execute_reply":"2023-07-11T15:10:11.333847Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"MAX_SEQUENCE_LENGTH = 500\nNUM_EPOCHS = 50\nSTART_TOKEN = '<START>'\nEND_TOKEN = '<END>'\nPADDING_TOKEN = '<PAD>'\nBATCH_SIZE =32\nd_model = 512\nffn_hidden = 2048\nnum_heads = 8\ndrop_prob = 0.1\nnum_layers = 2\nlearning_rate = 1e-4\nk=5\nload_model = False\nnum_columns = frames[0].shape[1]\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:11.335971Z","iopub.execute_input":"2023-07-11T15:10:11.336357Z","iopub.status.idle":"2023-07-11T15:10:11.381815Z","shell.execute_reply.started":"2023-07-11T15:10:11.336298Z","shell.execute_reply":"2023-07-11T15:10:11.380738Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"sos_eos_pad= {START_TOKEN: len(char2ord), END_TOKEN: len(char2ord)+1, PADDING_TOKEN: len(char2ord)+2}\nchar2ord.update(sos_eos_pad)\n\nphrase_vocab_size = len(char2ord)\n\ndisplay(char2ord)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:11.383018Z","iopub.execute_input":"2023-07-11T15:10:11.383542Z","iopub.status.idle":"2023-07-11T15:10:11.405532Z","shell.execute_reply.started":"2023-07-11T15:10:11.383504Z","shell.execute_reply":"2023-07-11T15:10:11.404502Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"{' ': 0,\n '!': 1,\n '#': 2,\n '$': 3,\n '%': 4,\n '&': 5,\n \"'\": 6,\n '(': 7,\n ')': 8,\n '*': 9,\n '+': 10,\n ',': 11,\n '-': 12,\n '.': 13,\n '/': 14,\n '0': 15,\n '1': 16,\n '2': 17,\n '3': 18,\n '4': 19,\n '5': 20,\n '6': 21,\n '7': 22,\n '8': 23,\n '9': 24,\n ':': 25,\n ';': 26,\n '=': 27,\n '?': 28,\n '@': 29,\n '[': 30,\n '_': 31,\n 'a': 32,\n 'b': 33,\n 'c': 34,\n 'd': 35,\n 'e': 36,\n 'f': 37,\n 'g': 38,\n 'h': 39,\n 'i': 40,\n 'j': 41,\n 'k': 42,\n 'l': 43,\n 'm': 44,\n 'n': 45,\n 'o': 46,\n 'p': 47,\n 'q': 48,\n 'r': 49,\n 's': 50,\n 't': 51,\n 'u': 52,\n 'v': 53,\n 'w': 54,\n 'x': 55,\n 'y': 56,\n 'z': 57,\n '~': 58,\n '<START>': 59,\n '<END>': 60,\n '<PAD>': 61}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocess","metadata":{}},{"cell_type":"code","source":"def sequence_pad(frame):\n    if len(frame)<MAX_SEQUENCE_LENGTH:\n        # Specify the number of empty rows to add\n        num_empty_rows = MAX_SEQUENCE_LENGTH-len(frame)\n        # Create empty rows filled with zeros\n        empty_rows = torch.zeros((num_empty_rows, frame.shape[1])).to(device)\n\n        # Concatenate the empty rows to the original array\n        frame = torch.cat((frame, empty_rows), dim=0)\n    else:\n        frame = frame[:MAX_SEQUENCE_LENGTH]\n        \n    # Check for NaN values in the tensor\n    nan_mask = torch.isnan(frame)\n\n    # Replace NaN values with 0 using torch.where\n    frame = torch.where(nan_mask, torch.tensor(0.0), frame)\n    return(frame)\n\ndef sequence_normalize(frame):\n    # Check for NaN values in the tensor\n    nan_mask = torch.isnan(frame)\n\n    # Replace NaN values with 0 using torch.where\n    frame = torch.where(nan_mask, torch.tensor(0.0), frame)\n\n    # Calculate the mean and standard deviation along the desired dimension (column-wise)\n    mean = torch.mean(frame, dim=0)\n    std = torch.std(frame, dim=0)\n\n    # Normalize the data by subtracting the mean and dividing by the standard deviation\n    normalized_frame = (frame-mean)/std\n    return normalized_frame","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:11.407269Z","iopub.execute_input":"2023-07-11T15:10:11.407636Z","iopub.status.idle":"2023-07-11T15:10:11.417436Z","shell.execute_reply.started":"2023-07-11T15:10:11.407605Z","shell.execute_reply":"2023-07-11T15:10:11.416442Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Masking","metadata":{}},{"cell_type":"code","source":"NEG_INFTY = -1e9\n\ndef create_masks(frame, phrase):\n    look_ahead_mask = torch.full([MAX_SEQUENCE_LENGTH, MAX_SEQUENCE_LENGTH] , True) # Creates a tensor with all values = True\n    #print(look_ahead_mask)\n    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1) # Upper traingle = True only\n    #print(look_ahead_mask)\n    encoder_padding_mask = torch.full([MAX_SEQUENCE_LENGTH, MAX_SEQUENCE_LENGTH] , False)\n    decoder_padding_mask_self_attention = torch.full([MAX_SEQUENCE_LENGTH, MAX_SEQUENCE_LENGTH] , False)\n    decoder_padding_mask_cross_attention = torch.full([MAX_SEQUENCE_LENGTH, MAX_SEQUENCE_LENGTH] , False)\n    #print(encoder_padding_mask)\n\n    frame_length, eng_sentence_length = len(frame), len(phrase)\n    frame_chars_to_padding_mask = np.arange(frame_length + 1, MAX_SEQUENCE_LENGTH)\n    eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, MAX_SEQUENCE_LENGTH)\n    encoder_padding_mask[:, frame_chars_to_padding_mask] = True\n    encoder_padding_mask[frame_chars_to_padding_mask, :] = True\n    decoder_padding_mask_self_attention[:, eng_chars_to_padding_mask] = True\n    decoder_padding_mask_self_attention[eng_chars_to_padding_mask, :] = True\n    decoder_padding_mask_cross_attention[:, eng_chars_to_padding_mask] = True\n    decoder_padding_mask_cross_attention[eng_chars_to_padding_mask, :] = True\n\n    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:11.419153Z","iopub.execute_input":"2023-07-11T15:10:11.419503Z","iopub.status.idle":"2023-07-11T15:10:11.432424Z","shell.execute_reply.started":"2023-07-11T15:10:11.419472Z","shell.execute_reply":"2023-07-11T15:10:11.431593Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class CustomDataset():\n    def __init__(self, frames, targets):\n        self.frames = frames\n        self.targets = targets\n    \n    def __len__(self):\n        return self.frames.shape[0]\n    \n    def tokenize_and_pad(self, target, use_start):\n        sentence_word_indices = np.array([char2ord[token] for token in list(target.lower())])\n        if use_start:\n            sentence_word_indices= np.insert(sentence_word_indices, 0, char2ord[START_TOKEN])\n        sentence_word_indices = np.append(sentence_word_indices, char2ord[END_TOKEN])\n        for _ in range(len(sentence_word_indices), MAX_SEQUENCE_LENGTH):\n            sentence_word_indices = np.append(sentence_word_indices, char2ord[PADDING_TOKEN])\n\n        return sentence_word_indices\n\n    def __getitem__(self, idx):\n        frame = torch.tensor(np.array(self.frames[idx])).to(device)\n        phrase = self.targets[idx]\n        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(frame, phrase)\n        frame = sequence_normalize(frame)\n        frame = sequence_pad(frame)\n        input_phrase = self.tokenize_and_pad(phrase, use_start = True)\n        target = self.tokenize_and_pad(phrase, use_start = False)\n        \n        return {\n            'frame': frame,\n            'input_phrase': torch.tensor(input_phrase).to(device),\n            'target': torch.tensor(target).to(device),\n            'encoder_self_attention_mask' : encoder_self_attention_mask.to(device), \n            'decoder_self_attention_mask' : decoder_self_attention_mask.to(device),\n            'decoder_cross_attention_mask' : decoder_cross_attention_mask.to(device) \n            \n        }","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:11.435607Z","iopub.execute_input":"2023-07-11T15:10:11.435862Z","iopub.status.idle":"2023-07-11T15:10:11.448797Z","shell.execute_reply.started":"2023-07-11T15:10:11.435839Z","shell.execute_reply":"2023-07-11T15:10:11.447873Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset = CustomDataset(frames, phrases)\nprint('Processed frame shape:',dataset[0]['frame'].shape)\nprint('Processed input_phrase shape:',dataset[0]['input_phrase'].shape)\nprint('Processed target shape:',dataset[0]['target'].shape)\nprint('encoder_self_attention_mask shape:',dataset[0]['encoder_self_attention_mask'].shape)\nprint('decoder_self_attention_mask shape:',dataset[0]['decoder_self_attention_mask'].shape)\nprint('decoder_cross_attention_mask shape:',dataset[0]['decoder_cross_attention_mask'].shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:11.454220Z","iopub.execute_input":"2023-07-11T15:10:11.454649Z","iopub.status.idle":"2023-07-11T15:10:14.682005Z","shell.execute_reply.started":"2023-07-11T15:10:11.454625Z","shell.execute_reply":"2023-07-11T15:10:14.681033Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Processed frame shape: torch.Size([500, 84])\nProcessed input_phrase shape: torch.Size([500])\nProcessed target shape: torch.Size([500])\nencoder_self_attention_mask shape: torch.Size([500, 500])\ndecoder_self_attention_mask shape: torch.Size([500, 500])\ndecoder_cross_attention_mask shape: torch.Size([500, 500])\n","output_type":"stream"}]},{"cell_type":"code","source":"dataloader = DataLoader(dataset=dataset, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:14.683546Z","iopub.execute_input":"2023-07-11T15:10:14.683867Z","iopub.status.idle":"2023-07-11T15:10:14.689190Z","shell.execute_reply.started":"2023-07-11T15:10:14.683836Z","shell.execute_reply":"2023-07-11T15:10:14.688333Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"for batch in dataloader:\n    print('Frames shape of a batch:',batch['frame'].shape)\n    print('Input phrase shape of a batch:',batch['input_phrase'].shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:14.690905Z","iopub.execute_input":"2023-07-11T15:10:14.691859Z","iopub.status.idle":"2023-07-11T15:10:15.257697Z","shell.execute_reply.started":"2023-07-11T15:10:14.691707Z","shell.execute_reply":"2023-07-11T15:10:15.256381Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Frames shape of a batch: torch.Size([32, 500, 84])\nInput phrase shape of a batch: torch.Size([32, 500])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_sequence_length):\n        super().__init__()\n        self.max_sequence_length = max_sequence_length\n        self.d_model = d_model\n\n    def forward(self):\n        even_i = torch.arange(0, self.d_model, 2).float()\n        denominator = torch.pow(10000, even_i/self.d_model)\n        position = (torch.arange(self.max_sequence_length)\n                          .reshape(self.max_sequence_length, 1))\n        even_PE = torch.sin(position / denominator)\n        odd_PE = torch.cos(position / denominator)\n        stacked = torch.stack([even_PE, odd_PE], dim=2)\n        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n        return PE","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:15.259197Z","iopub.execute_input":"2023-07-11T15:10:15.259663Z","iopub.status.idle":"2023-07-11T15:10:15.273270Z","shell.execute_reply.started":"2023-07-11T15:10:15.259560Z","shell.execute_reply":"2023-07-11T15:10:15.272283Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class CustomEmbedding(nn.Module):\n    def __init__(self, max_sequence_length, num_columns, d_model, encoder_embed):\n        super().__init__()\n        self.max_sequence_length = max_sequence_length\n        self.num_columns = num_columns\n        if encoder_embed:\n            #self.embedding = nn.Linear(num_columns, d_model)\n            self.conv1 = nn.Conv1d(in_channels=num_columns, out_channels = 1024, kernel_size = 3, stride=1, padding = 'same').to(device)\n            self.conv2 = nn.Conv1d(in_channels=1024, out_channels = d_model, kernel_size = 3, stride=1, padding = 'same').to(device)\n        else:\n            self.embedding = nn.Embedding(max_sequence_length, d_model).to(device)\n\n        self.position_encoder = PositionalEncoding(d_model, max_sequence_length)\n        self.dropout = nn.Dropout(p=0.1).to(device)\n    \n    def forward(self, x, encoder_embed):\n        if encoder_embed:\n            x = torch.transpose(x, -2, -1)\n            x = self.conv1(x)\n            x = self.conv2(x)\n            x = torch.transpose(x, -2, -1).to(device)\n        else:\n            x = self.embedding(x)\n        pos = self.position_encoder().to(device)\n        x = self.dropout(x + pos)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:15.274694Z","iopub.execute_input":"2023-07-11T15:10:15.275534Z","iopub.status.idle":"2023-07-11T15:10:15.286946Z","shell.execute_reply.started":"2023-07-11T15:10:15.275499Z","shell.execute_reply":"2023-07-11T15:10:15.285919Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"'''class CustomEmbedding(nn.Module):\n    def __init__(self, max_sequence_length, num_columns, d_model, encoder_embed):\n        super().__init__()\n        self.max_sequence_length = max_sequence_length\n        self.num_columns = num_columns\n        if encoder_embed:\n            self.embedding = nn.Linear(num_columns, d_model).to(device)\n        else:\n            self.embedding = nn.Embedding(max_sequence_length, d_model).to(device)\n        self.position_encoder = PositionalEncoding(d_model, max_sequence_length)\n        self.dropout = nn.Dropout(p=0.1)\n        \n    def forward(self, x):\n        x = self.embedding(x)\n        pos = self.position_encoder().to(device)\n        x = self.dropout(x + pos)\n        return x'''","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:15.289860Z","iopub.execute_input":"2023-07-11T15:10:15.290119Z","iopub.status.idle":"2023-07-11T15:10:15.306492Z","shell.execute_reply.started":"2023-07-11T15:10:15.290097Z","shell.execute_reply":"2023-07-11T15:10:15.305513Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'class CustomEmbedding(nn.Module):\\n    def __init__(self, max_sequence_length, num_columns, d_model, encoder_embed):\\n        super().__init__()\\n        self.max_sequence_length = max_sequence_length\\n        self.num_columns = num_columns\\n        if encoder_embed:\\n            self.embedding = nn.Linear(num_columns, d_model).to(device)\\n        else:\\n            self.embedding = nn.Embedding(max_sequence_length, d_model).to(device)\\n        self.position_encoder = PositionalEncoding(d_model, max_sequence_length)\\n        self.dropout = nn.Dropout(p=0.1)\\n        \\n    def forward(self, x):\\n        x = self.embedding(x)\\n        pos = self.position_encoder().to(device)\\n        x = self.dropout(x + pos)\\n        return x'"},"metadata":{}}]},{"cell_type":"code","source":"custom = CustomEmbedding(500, 84, 512,True)\ninput = torch.randn(32,500,84).to(device)\ncustom(input, True).shape","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:15.307928Z","iopub.execute_input":"2023-07-11T15:10:15.308590Z","iopub.status.idle":"2023-07-11T15:10:20.216304Z","shell.execute_reply.started":"2023-07-11T15:10:15.308559Z","shell.execute_reply":"2023-07-11T15:10:20.215202Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"torch.Size([32, 500, 512])"},"metadata":{}}]},{"cell_type":"code","source":"class LayerNormalization(nn.Module):\n    def __init__(self, parameters_shape, eps=1e-5):\n        super().__init__()\n        self.parameters_shape=parameters_shape\n        self.eps=eps\n        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n\n    def forward(self, inputs):\n        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n        mean = inputs.mean(dim=dims, keepdim=True)\n        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n        std = (var + self.eps).sqrt()\n        y = (inputs - mean) / std\n        out = self.gamma * y + self.beta\n        return out\n\n\nclass PositionwiseFeedForward(nn.Module):\n    def __init__(self, d_model, hidden, drop_prob=0.1):\n        super(PositionwiseFeedForward, self).__init__()\n        self.linear1 = nn.Linear(d_model, hidden)\n        self.linear2 = nn.Linear(hidden, d_model)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=drop_prob)\n\n    def forward(self, x):\n        x = self.linear1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.linear2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:20.217942Z","iopub.execute_input":"2023-07-11T15:10:20.218310Z","iopub.status.idle":"2023-07-11T15:10:20.229739Z","shell.execute_reply.started":"2023-07-11T15:10:20.218277Z","shell.execute_reply":"2023-07-11T15:10:20.228732Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def scaled_dot_product(q, k, v, mask=None):\n    d_k = q.size()[-1]\n    scaled = torch.matmul(q, k.transpose(-1, -2)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float))\n    if mask is not None:\n        scaled = scaled.permute(1, 0, 2, 3) + mask\n        scaled = scaled.permute(1, 0, 2, 3)\n    attention = F.softmax(scaled, dim=-1)\n    values = torch.matmul(attention, v)\n    return values, attention\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.head_dim = d_model // num_heads\n        self.qkv_layer = nn.Linear(d_model , 3 * d_model)\n        self.linear_layer = nn.Linear(d_model, d_model)\n\n    def forward(self, x, mask):\n        batch_size, sequence_length, d_model = x.size()\n        qkv = self.qkv_layer(x)\n        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n        qkv = qkv.permute(0, 2, 1, 3)\n        q, k, v = qkv.chunk(3, dim=-1)\n        values, attention = scaled_dot_product(q, k, v, mask)\n        values = values.permute(0, 2, 1, 3).reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n        out = self.linear_layer(values)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:20.232039Z","iopub.execute_input":"2023-07-11T15:10:20.232424Z","iopub.status.idle":"2023-07-11T15:10:20.245481Z","shell.execute_reply.started":"2023-07-11T15:10:20.232393Z","shell.execute_reply":"2023-07-11T15:10:20.244371Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class MultiHeadCrossAttention(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.head_dim = d_model // num_heads\n        self.kv_layer = nn.Linear(d_model , 2 * d_model)\n        self.q_layer = nn.Linear(d_model , d_model)\n        self.linear_layer = nn.Linear(d_model, d_model)\n\n    def forward(self, x, y, mask):\n        batch_size, sequence_length, d_model = x.size() # in practice, this is the same for both languages...so we can technically combine with normal attention\n        kv = self.kv_layer(x)\n        q = self.q_layer(y)\n        kv = kv.reshape(batch_size, sequence_length, self.num_heads, 2 * self.head_dim)\n        q = q.reshape(batch_size, sequence_length, self.num_heads, self.head_dim)\n        kv = kv.permute(0, 2, 1, 3)\n        q = q.permute(0, 2, 1, 3)\n        k, v = kv.chunk(2, dim=-1)\n        values, attention = scaled_dot_product(q, k, v, mask) # We don't need the mask for cross attention, removing in outer function!\n        values = values.permute(0, 2, 1, 3).reshape(batch_size, sequence_length, d_model)\n        out = self.linear_layer(values)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:20.246797Z","iopub.execute_input":"2023-07-11T15:10:20.247464Z","iopub.status.idle":"2023-07-11T15:10:20.263292Z","shell.execute_reply.started":"2023-07-11T15:10:20.247396Z","shell.execute_reply":"2023-07-11T15:10:20.262448Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class EncoderLayer(nn.Module):\n    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n        super(EncoderLayer, self).__init__()\n        self.attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n        self.norm1 = LayerNormalization(parameters_shape=[d_model])\n        self.dropout1 = nn.Dropout(p=drop_prob)\n        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n        self.norm2 = LayerNormalization(parameters_shape=[d_model])\n        self.dropout2 = nn.Dropout(p=drop_prob)\n\n    def forward(self, x, self_attention_mask):\n        residual_x = x.clone()\n        x = self.attention(x, mask=self_attention_mask)\n        x = self.dropout1(x)\n        x = self.norm1(x + residual_x)\n        residual_x = x.clone()\n        x = self.ffn(x)\n        x = self.dropout2(x)\n        x = self.norm2(x + residual_x)\n        return x\n    \nclass SequentialEncoder(nn.Sequential):\n    def forward(self, *inputs):\n        x, self_attention_mask  = inputs\n        for module in self._modules.values():\n            x = module(x, self_attention_mask)\n        return x\n        \nclass Encoder(nn.Module):\n    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, num_columns, encoder_embed=True):\n        super().__init__()\n        self.encoder_embedding = CustomEmbedding(max_sequence_length, num_columns, d_model, encoder_embed=True)\n        self.layers = SequentialEncoder(*[EncoderLayer(d_model, ffn_hidden, num_heads, drop_prob)\n                                      for _ in range(num_layers)])\n    \n    def forward(self, x, self_attention_mask):\n        x = self.encoder_embedding(x, encoder_embed = True)\n        x = self.layers(x, self_attention_mask)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:20.265402Z","iopub.execute_input":"2023-07-11T15:10:20.266389Z","iopub.status.idle":"2023-07-11T15:10:20.280582Z","shell.execute_reply.started":"2023-07-11T15:10:20.266336Z","shell.execute_reply":"2023-07-11T15:10:20.279447Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class DecoderLayer(nn.Module):\n    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n        super(DecoderLayer, self).__init__()\n        self.self_attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n        self.layer_norm1 = LayerNormalization(parameters_shape=[d_model])\n        self.dropout1 = nn.Dropout(p=drop_prob)\n\n        self.encoder_decoder_attention = MultiHeadCrossAttention(d_model=d_model, num_heads=num_heads)\n        self.layer_norm2 = LayerNormalization(parameters_shape=[d_model])\n        self.dropout2 = nn.Dropout(p=drop_prob)\n\n        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n        self.layer_norm3 = LayerNormalization(parameters_shape=[d_model])\n        self.dropout3 = nn.Dropout(p=drop_prob)\n\n    def forward(self, x, y, self_attention_mask, cross_attention_mask):\n        _y = y.clone()\n        y = self.self_attention(y, mask=self_attention_mask)\n        y = self.dropout1(y)\n        y = self.layer_norm1(y + _y)\n\n        _y = y.clone()\n        y = self.encoder_decoder_attention(x, y, mask=cross_attention_mask)\n        y = self.dropout2(y)\n        y = self.layer_norm2(y + _y)\n\n        _y = y.clone()\n        y = self.ffn(y)\n        y = self.dropout3(y)\n        y = self.layer_norm3(y + _y)\n        return y\n\n\nclass SequentialDecoder(nn.Sequential):\n    def forward(self, *inputs):\n        x, y, self_attention_mask, cross_attention_mask = inputs\n        for module in self._modules.values():\n            y = module(x, y, self_attention_mask, cross_attention_mask)\n        return y\n\nclass Decoder(nn.Module):\n    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, num_columns, encoder_embed=False):\n        super().__init__()\n        self.decoder_embedding = CustomEmbedding(max_sequence_length, num_columns, d_model, encoder_embed=False)\n        self.layers = SequentialDecoder(*[DecoderLayer(d_model, ffn_hidden, num_heads, drop_prob) for _ in range(num_layers)])\n\n    def forward(self, x, y, self_attention_mask, cross_attention_mask):\n        y = self.decoder_embedding(y, encoder_embed = False)\n        y = self.layers(x, y, self_attention_mask, cross_attention_mask)\n        return y","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:20.282301Z","iopub.execute_input":"2023-07-11T15:10:20.282771Z","iopub.status.idle":"2023-07-11T15:10:20.299989Z","shell.execute_reply.started":"2023-07-11T15:10:20.282740Z","shell.execute_reply":"2023-07-11T15:10:20.298946Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self,d_model,\n                          ffn_hidden,\n                          num_heads,\n                          drop_prob,\n                          num_layers,\n                          max_sequence_length,\n                          num_columns,\n                          phrase_vocab_size):\n        super().__init__()\n        self.encoder = Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, num_columns, encoder_embed=True)\n        self.decoder = Decoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, num_columns, encoder_embed=False)\n        self.linear = nn.Linear(d_model, phrase_vocab_size)\n        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    def forward(self,\n                x,\n                y,\n                encoder_self_attention_mask=None,\n                decoder_self_attention_mask=None,\n                decoder_cross_attention_mask=None): # x, y are batch of sentences\n        x = self.encoder(x, encoder_self_attention_mask)\n        out = self.decoder(x, y, decoder_self_attention_mask, decoder_cross_attention_mask)\n        out = self.linear(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:20.302429Z","iopub.execute_input":"2023-07-11T15:10:20.303057Z","iopub.status.idle":"2023-07-11T15:10:20.316614Z","shell.execute_reply.started":"2023-07-11T15:10:20.303026Z","shell.execute_reply":"2023-07-11T15:10:20.315029Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"transformer = Transformer(d_model,ffn_hidden,\n                          num_heads,\n                          drop_prob,\n                          num_layers,\n                          MAX_SEQUENCE_LENGTH,\n                         num_columns,\n                        phrase_vocab_size)\ndisplay(transformer)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:20.319493Z","iopub.execute_input":"2023-07-11T15:10:20.320179Z","iopub.status.idle":"2023-07-11T15:10:20.487297Z","shell.execute_reply.started":"2023-07-11T15:10:20.320143Z","shell.execute_reply":"2023-07-11T15:10:20.486254Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Transformer(\n  (encoder): Encoder(\n    (encoder_embedding): CustomEmbedding(\n      (conv1): Conv1d(84, 1024, kernel_size=(3,), stride=(1,), padding=same)\n      (conv2): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=same)\n      (position_encoder): PositionalEncoding()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (layers): SequentialEncoder(\n      (0): EncoderLayer(\n        (attention): MultiHeadAttention(\n          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (norm1): LayerNormalization()\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (ffn): PositionwiseFeedForward(\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (relu): ReLU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (norm2): LayerNormalization()\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n      (1): EncoderLayer(\n        (attention): MultiHeadAttention(\n          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (norm1): LayerNormalization()\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (ffn): PositionwiseFeedForward(\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (relu): ReLU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (norm2): LayerNormalization()\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (decoder): Decoder(\n    (decoder_embedding): CustomEmbedding(\n      (embedding): Embedding(500, 512)\n      (position_encoder): PositionalEncoding()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (layers): SequentialDecoder(\n      (0): DecoderLayer(\n        (self_attention): MultiHeadAttention(\n          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (layer_norm1): LayerNormalization()\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (encoder_decoder_attention): MultiHeadCrossAttention(\n          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (layer_norm2): LayerNormalization()\n        (dropout2): Dropout(p=0.1, inplace=False)\n        (ffn): PositionwiseFeedForward(\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (relu): ReLU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (layer_norm3): LayerNormalization()\n        (dropout3): Dropout(p=0.1, inplace=False)\n      )\n      (1): DecoderLayer(\n        (self_attention): MultiHeadAttention(\n          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (layer_norm1): LayerNormalization()\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (encoder_decoder_attention): MultiHeadCrossAttention(\n          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (layer_norm2): LayerNormalization()\n        (dropout2): Dropout(p=0.1, inplace=False)\n        (ffn): PositionwiseFeedForward(\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (relu): ReLU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (layer_norm3): LayerNormalization()\n        (dropout3): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (linear): Linear(in_features=512, out_features=62, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(ignore_index=char2ord[PADDING_TOKEN],\n                              reduction='none')\n\n# When computing the loss, we are ignoring cases when the label is the padding token\nfor params in transformer.parameters():\n    if params.dim() > 1:\n        nn.init.xavier_uniform_(params)\n\noptimizer = torch.optim.Adam(transformer.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:20.489150Z","iopub.execute_input":"2023-07-11T15:10:20.490172Z","iopub.status.idle":"2023-07-11T15:10:20.601450Z","shell.execute_reply.started":"2023-07-11T15:10:20.490137Z","shell.execute_reply":"2023-07-11T15:10:20.600514Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(model, dataloader, criterion, optimizer, device):\n    steps = len(dataloader)\n    total_train_epoch_loss = 0\n    total_train_epoch_acc = 0\n    transformer.train()\n    for batch_idx, batch in tqdm(enumerate(dataloader)):\n        frame = batch['frame']\n        input_phrase = batch['input_phrase']\n        targets = batch['target'].view(-1)\n        encoder_self_attention_mask = batch['encoder_self_attention_mask']\n        decoder_self_attention_mask = batch['decoder_self_attention_mask']\n        decoder_cross_attention_mask = batch['decoder_cross_attention_mask']\n        output = model(frame, input_phrase, encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask)\n\n        batch_loss = criterion(output.view(-1, phrase_vocab_size).to(device), targets.to(device)).to(device)\n        valid_indices = torch.where(targets == char2ord[PADDING_TOKEN], False, True)\n        batch_loss = batch_loss.sum() / valid_indices.sum()\n\n        optimizer.zero_grad()\n        \n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        # Backpropagation\n        batch_loss.backward() # Gradients calculation\n        optimizer.step() # Updation of weights\n        batch_acc = (output.argmax(dim=2) == batch['target']).sum() / valid_indices.sum()\n\n        total_train_epoch_loss += batch_loss\n        total_train_epoch_acc += batch_acc\n\n        #total_train_samples+= len(batch['target'].view(-1))\n\n        #print(f'Batch train Accuracy: {batch_acc} | Batch train Loss: {batch_loss} | Batch:{batch_idx}')\n    train_epoch_acc = total_train_epoch_acc / steps\n    train_epoch_loss = total_train_epoch_loss / steps\n    return train_epoch_acc, train_epoch_loss","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:20.603040Z","iopub.execute_input":"2023-07-11T15:10:20.603662Z","iopub.status.idle":"2023-07-11T15:10:20.614162Z","shell.execute_reply.started":"2023-07-11T15:10:20.603629Z","shell.execute_reply":"2023-07-11T15:10:20.613256Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, dataloader, device):\n    steps = len(dataloader)\n    total_val_epoch_loss = 0\n    total_val_epoch_acc = 0\n    total_val_samples = 0\n    transformer.eval()\n    with torch.no_grad():\n        for batch_idx, batch in tqdm(enumerate(dataloader)):\n            frame = batch['frame']\n            input_phrase = batch['input_phrase']\n            targets = batch['target'].view(-1)\n            encoder_self_attention_mask = batch['encoder_self_attention_mask']\n            decoder_self_attention_mask = batch['decoder_self_attention_mask']\n            decoder_cross_attention_mask = batch['decoder_cross_attention_mask']\n            output = model(frame, input_phrase, encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask)\n\n            batch_loss = criterion(output.view(-1, phrase_vocab_size).to(device), targets.to(device)).to(device)\n            valid_indices = torch.where(targets == char2ord[PADDING_TOKEN], False, True)\n            batch_loss = batch_loss.sum() / valid_indices.sum()\n\n            batch_acc = (output.argmax(dim=2) == batch['target']).sum() / valid_indices.sum()\n\n            total_val_epoch_loss += batch_loss\n            total_val_epoch_acc += batch_acc\n    \n        #total_val_samples+= len(batch['target'].view(-1))\n\n            #print(f'Batch val Accuracy: {batch_acc} | Batch val Loss: {batch_loss} | Batch:{batch_idx}')\n    val_epoch_acc = total_val_epoch_acc / steps\n    val_epoch_loss = total_val_epoch_loss / steps\n    return val_epoch_acc, val_epoch_loss","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:20.615701Z","iopub.execute_input":"2023-07-11T15:10:20.616030Z","iopub.status.idle":"2023-07-11T15:10:20.632446Z","shell.execute_reply.started":"2023-07-11T15:10:20.616001Z","shell.execute_reply":"2023-07-11T15:10:20.631286Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def save_checkpoint (state, filename=\"/kaggle/working/my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    torch.save(state, filename)\n    \ndef load_checkpoint (model, optimizer, checkpoint):\n    print(\"=> Loading checkpoint\")\n    model.load_state_dict(checkpoint['state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer'])\n\nif load_model:\n    load_checkpoint (transformer, optimizer, torch.load(\"/kaggle/working/my_checkpoint.pth.tar\"))","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:20.633978Z","iopub.execute_input":"2023-07-11T15:10:20.634385Z","iopub.status.idle":"2023-07-11T15:10:20.648984Z","shell.execute_reply.started":"2023-07-11T15:10:20.634353Z","shell.execute_reply":"2023-07-11T15:10:20.647970Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"transformer.to(device)\nkf = KFold(n_splits=k)\n# Iterate over the folds\nfor fold, (train_index, val_index) in enumerate(kf.split(dataset)):\n    print(f\"Training on fold {fold+1}/{k}...\")\n\n    # Create data loaders for training and validation\n    train_dataset = Subset(dataset, train_index)\n    val_dataset = Subset(dataset, val_index)\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n    for epoch in range(NUM_EPOCHS):\n        print(f'Epoch {epoch + 1}/{NUM_EPOCHS}')\n        \n        checkpoint = {'state_dict' : transformer.state_dict(), 'optimizer': optimizer.state_dict()}\n        save_checkpoint (checkpoint)\n        train_epoch_acc, train_epoch_loss = train_one_epoch(transformer, train_loader, criterion, optimizer, device)\n        print('-----------------------------------------------------------------')\n        print()\n        print(f'Epoch train Accuracy:{train_epoch_acc} | Epoch train Loss:{train_epoch_loss} | Epoch:{epoch + 1}')\n        \n        val_epoch_acc, val_epoch_loss = eval_model(transformer, val_loader, device)\n        print(f'Epoch val Accuracy:{val_epoch_acc} | Epoch val Loss:{val_epoch_loss} | Epoch:{epoch + 1}')\n        print()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:10:20.654645Z","iopub.execute_input":"2023-07-11T15:10:20.654928Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Training on fold 1/5...\nEpoch 1/50\n=> Saving checkpoint\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b6adbf72bf74a04b7bfaf7c5a48ad7d"}},"metadata":{}},{"name":"stdout","text":"-----------------------------------------------------------------\n\nEpoch train Accuracy:0.2443910539150238 | Epoch train Loss:2.5944783687591553 | Epoch:1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"590fb46ce7b949efb6c659814411881d"}},"metadata":{}},{"name":"stdout","text":"Epoch val Accuracy:0.32722100615501404 | Epoch val Loss:2.2152366638183594 | Epoch:1\n\nEpoch 2/50\n=> Saving checkpoint\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b90d09932a046fe81b6777fe3c755f4"}},"metadata":{}},{"name":"stdout","text":"-----------------------------------------------------------------\n\nEpoch train Accuracy:0.36517980694770813 | Epoch train Loss:2.0930991172790527 | Epoch:2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"588b202a373447deb2733f3ca4ddf1ec"}},"metadata":{}},{"name":"stdout","text":"Epoch val Accuracy:0.4434088170528412 | Epoch val Loss:1.8328925371170044 | Epoch:2\n\nEpoch 3/50\n=> Saving checkpoint\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffbb8d27ced04034a930280f947d5e39"}},"metadata":{}},{"name":"stdout","text":"-----------------------------------------------------------------\n\nEpoch train Accuracy:0.47233662009239197 | Epoch train Loss:1.7414511442184448 | Epoch:3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03bd67aa1593426588250f9c517d84da"}},"metadata":{}},{"name":"stdout","text":"Epoch val Accuracy:0.5325650572776794 | Epoch val Loss:1.5448418855667114 | Epoch:3\n\nEpoch 4/50\n=> Saving checkpoint\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b84600551d564fc2886b7630031cc6bb"}},"metadata":{}},{"name":"stdout","text":"-----------------------------------------------------------------\n\nEpoch train Accuracy:0.539319634437561 | Epoch train Loss:1.5252717733383179 | Epoch:4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d94711889d248538a8d41822bae4102"}},"metadata":{}},{"name":"stdout","text":"Epoch val Accuracy:0.5865300297737122 | Epoch val Loss:1.3785041570663452 | Epoch:4\n\nEpoch 5/50\n=> Saving checkpoint\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40341706e8894715af05cbf64a863167"}},"metadata":{}}]},{"cell_type":"code","source":"'''import shutil\nshutil.rmtree('/kaggle/working')'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}